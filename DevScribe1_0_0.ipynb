{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshameTheDestroyer/DevScribe/blob/main/DevScribe1_0_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9Ax0j76I2ku",
        "outputId": "38ead322-ba83-44ed-ef24-6cd345609a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.6/329.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.1/210.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.4/457.4 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.6/426.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.9/160.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.3/233.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.8/358.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.43.0, but you have google-auth 2.45.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-openai langchain-community pypdf faiss-cpu sentence-transformers chromadb python-dotenv langchain-experimental langchain-google-genai ragas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrAvwmYkbjSB",
        "outputId": "df4bdcc9-aa88-4272-ae79-5f0c3d81f64c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA0wW7Lbbity"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U84W__Ooa1Uq"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lXJ0DT11moj2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = userdata.get(\"LANGSMITH_API_KEY\")\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"DevScribe\"\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.4)\n",
        "deterministic_model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzJG9LVgv07a"
      },
      "source": [
        "# Defining Company's Knowledge Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8VtDEjGsv4lH"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "knowledge_base = [\n",
        "    Document(\n",
        "        page_content=\"\"\"# Style Guide\\n\\n## Variable Naming\\n\\nAll variables must be snake_case. For constants, use SCREAMING_SNAKE_CASE. Avoid using camelCase or PascalCase for variable names.\\n\\n## Docstrings\\n\\nDocstrings must use Google Format. Every function and method should have a docstring describing its purpose, arguments, and return values. Examples should be included where appropriate.\\n\\n## Code Formatting\\n\\nUse a maximum line length of 100 characters. Adhere to PEP 8 guidelines for all Python code. Run an auto-formatter like Black before committing code.\"\"\",\n",
        "        metadata={\"source\": \"style_guide.md\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"\"\"# Security Policy\\n\\n## Logging\\n\\nNever use `print()` for debugging or logging in production code. Always use `app_logger` for all logging purposes. Configure `app_logger` to output to a centralized logging system.\\n\\n## API Keys\\n\\nAPI keys and other sensitive credentials must always be loaded from environment variables (e.g., `.env` files or platform-specific secrets management systems) and never hardcoded in the codebase. Ensure `.env` files are not committed to version control.\\n\\n## Input Validation\\n\\nAll user inputs must be thoroughly validated on the server-side to prevent common vulnerabilities like SQL injection, XSS, and command injection.\"\"\",\n",
        "        metadata={\"source\": \"security_policy.md\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"\"\"# Legacy Deprecation\\n\\n## Data Handling\\n\\nDo not use `pandas` for data manipulation in new projects; use `polars` instead for its performance benefits and modern API. Migrate existing `pandas` code to `polars` where feasible.\\n\\n## Old Authentication System\\n\\nThe `LegacyAuth` module is deprecated and will be removed by Q4 2024. All new authentication flows must use `OAuth2Client`. Migrate existing services to `OAuth2Client` as soon as possible.\"\"\",\n",
        "        metadata={\"source\": \"legacy_deprecation.md\"}\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hf0B_qhE0ux"
      },
      "source": [
        "# Reading Company's Knowledge Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMZIY2BqE4Id",
        "outputId": "1b28da18-5b8a-4f75-fc34-1318dfcf5e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Chunk 1 ---\n",
            "Content: 'All variables must be snake_case. For constants, use SCREAMING_SNAKE_CASE. Avoid using camelCase or PascalCase for variable names.'\n",
            "Metadata: {'Header 1': 'Style Guide', 'Header 2': 'Variable Naming'}\n",
            "\n",
            "--- Chunk 2 ---\n",
            "Content: 'Docstrings must use Google Format. Every function and method should have a docstring describing its purpose, arguments, and return values. Examples should be included where appropriate.'\n",
            "Metadata: {'Header 1': 'Style Guide', 'Header 2': 'Docstrings'}\n",
            "\n",
            "--- Chunk 3 ---\n",
            "Content: 'Use a maximum line length of 100 characters. Adhere to PEP 8 guidelines for all Python code. Run an auto-formatter like Black before committing code.'\n",
            "Metadata: {'Header 1': 'Style Guide', 'Header 2': 'Code Formatting'}\n",
            "\n",
            "--- Chunk 1 ---\n",
            "Content: 'Never use `print()` for debugging or logging in production code. Always use `app_logger` for all logging purposes. Configure `app_logger` to output to a centralized logging system.'\n",
            "Metadata: {'Header 1': 'Security Policy', 'Header 2': 'Logging'}\n",
            "\n",
            "--- Chunk 2 ---\n",
            "Content: 'API keys and other sensitive credentials must always be loaded from environment variables (e.g., `.env` files or platform-specific secrets management systems) and never hardcoded in the codebase. Ensure `.env` files are not committed to version control.'\n",
            "Metadata: {'Header 1': 'Security Policy', 'Header 2': 'API Keys'}\n",
            "\n",
            "--- Chunk 3 ---\n",
            "Content: 'All user inputs must be thoroughly validated on the server-side to prevent common vulnerabilities like SQL injection, XSS, and command injection.'\n",
            "Metadata: {'Header 1': 'Security Policy', 'Header 2': 'Input Validation'}\n",
            "\n",
            "--- Chunk 1 ---\n",
            "Content: 'Do not use `pandas` for data manipulation in new projects; use `polars` instead for its performance benefits and modern API. Migrate existing `pandas` code to `polars` where feasible.'\n",
            "Metadata: {'Header 1': 'Legacy Deprecation', 'Header 2': 'Data Handling'}\n",
            "\n",
            "--- Chunk 2 ---\n",
            "Content: 'The `LegacyAuth` module is deprecated and will be removed by Q4 2024. All new authentication flows must use `OAuth2Client`. Migrate existing services to `OAuth2Client` as soon as possible.'\n",
            "Metadata: {'Header 1': 'Legacy Deprecation', 'Header 2': 'Old Authentication System'}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
        "\n",
        "headers_to_split_on = [\n",
        "    (\"#\", \"Header 1\"),\n",
        "    (\"##\", \"Header 2\"),\n",
        "    (\"###\", \"Header 3\"),\n",
        "]\n",
        "\n",
        "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
        "\n",
        "chunks = []\n",
        "for document in knowledge_base:\n",
        "  md_header_splits = markdown_splitter.split_text(document.page_content)\n",
        "  for i, chunk in enumerate(md_header_splits):\n",
        "    chunks.append(chunk)\n",
        "    print(f\"--- Chunk {i+1} ---\")\n",
        "    print(f\"Content: '{chunk.page_content.strip()}'\")\n",
        "    print(f\"Metadata: {chunk.metadata}\\n\")\n",
        "\n",
        "vectorstore = FAISS.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embeddings,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkM5jYrD0Err"
      },
      "source": [
        "# Creating Multiquery Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9166dc58"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_classic.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3, \"search_type\": \"mmr\"})\n",
        "\n",
        "mq_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"You are an AI language model assistant. Your task is\n",
        "    to generate 3 different versions of search queries based on the provided code snippet.\n",
        "    The goal is to identify potential flaws, security vulnerabilities, style guide violations,\n",
        "    or uses of deprecated features within the code, or any other policy violations, according\n",
        "    to company policies. Provide these alternative queries separated by newlines.\n",
        "    Original code snippet: {question}\"\"\".\n",
        ")\n",
        "\n",
        "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=retriever, llm=deterministic_model, prompt=mq_prompt\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlekUDW-6ouM"
      },
      "source": [
        "# Defining Refactorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f990bf4b",
        "outputId": "11690d8c-1d3a-492d-e46e-f1e512f46e00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAGRefactorSuggestion Pydantic schema defined.\n"
          ]
        }
      ],
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class RAGRefactorSuggestion(BaseModel):\n",
        "    critique: str = Field(description=\"Critique of the original code.\")\n",
        "    refactored_code: str = Field(description=\"The refactored code.\")\n",
        "    changes_made: str = Field(description=\"Explanation of changes made.\")\n",
        "    policy_citations: List[str] = Field(description=\"List of policy documents that justify the refactoring.\")\n",
        "\n",
        "print(\"RAGRefactorSuggestion Pydantic schema defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "f9919b14"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "refactor_prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=\"\"\"You are an expert code refactorer. Your task is to identify potential flaws,\n",
        "    security vulnerabilities, style guide violations, or uses of deprecated features within the provided code snippet,\n",
        "    or any other policy violations, based ONLY on the provided context.\n",
        "\n",
        "    Critique the code, suggest a refactored version, explain the changes made,\n",
        "    and cite the specific policy documents from the context that justify your refactoring.\n",
        "\n",
        "    Context: {context}\n",
        "\n",
        "    Code Snippet: {question}\n",
        "\n",
        "    Your output MUST be a JSON object conforming to the following schema:\n",
        "    {{\n",
        "        \"critique\": \"<your critique here>\",\n",
        "        \"refactored_code\": \"<your refactored code here>\",\n",
        "        \"changes_made\": \"<explanation of changes>\",\n",
        "        \"policy_citations\": [\n",
        "            \"<policy document citation 1 (e.g., style_guide.md, Security Policy > API Keys, Legacy Deprecation > Data Handling)>\",\n",
        "            \"<policy document citation 2>\"\n",
        "        ]\n",
        "    }}\n",
        "    Ensure you provide at least one policy citation if a refactoring is suggested. If no refactoring is needed, just provide a positive critique and empty lists for changes and citations. Answer based ONLY on the provided context.\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "refactor_chain = (\n",
        "    {\n",
        "        \"context\": multiquery_retriever,\n",
        "        \"question\": RunnablePassthrough(),\n",
        "    }\n",
        "    | refactor_prompt\n",
        "    | deterministic_model\n",
        "    | JsonOutputParser(pydantic_object=RAGRefactorSuggestion)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okV1gYhf7A5P"
      },
      "source": [
        "# Example Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b61379e",
        "outputId": "27615814-c6a9-4651-81c1-984e365bfd3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'critique': 'The provided code snippet contains two main issues based on the established policies. Firstly, it uses `print()` for debugging or logging purposes, which is explicitly prohibited in production code. All logging should utilize the `app_logger`. Secondly, the `user_id` parameter, which can be considered user input, lacks server-side validation. This omission could potentially expose the application to various input-related vulnerabilities if `user_id` originates from an untrusted source.', 'refactored_code': 'def get_user_data(user_id):\\n    # Input Validation: Ensure user_id is a positive integer\\n    if not isinstance(user_id, int) or user_id <= 0:\\n        app_logger.warning(f\"Invalid user ID format or value provided: {user_id}. User ID must be a positive integer.\")\\n        return None\\n\\n    app_logger.info(f\\'Fetching data for user: {user_id}\\')\\n    # Simulate fetching data from a database\\n    if user_id == 1:\\n        return {\\'id\\': 1, \\'name\\': \\'Alice\\', \\'email\\': \\'alice@example.com\\'}\\n    else:\\n        app_logger.info(f\\'No data found for user ID: {user_id}\\')\\n        return None', 'changes_made': '1.  **Replaced `print()` with `app_logger.info()`:** The original `print()` statement was replaced with a call to `app_logger.info()` to ensure all logging adheres to the centralized logging system policy.\\n2.  **Added Input Validation for `user_id`:** Implemented a check to validate that `user_id` is an integer and a positive value. If the validation fails, a warning is logged using `app_logger.warning()`, and `None` is returned, preventing invalid or malicious inputs from proceeding.\\n3.  **Enhanced Logging for No Data Found:** Added an `app_logger.info()` call for the scenario where no user data is found, providing more comprehensive logging.', 'policy_citations': ['Security Policy > Logging (Document ID: 8830b55f-3418-4adc-97d5-553c67469e03)', 'Security Policy > Input Validation (Document ID: f060193c-6629-48f4-bb74-e28878e1fb2b)']}\n"
          ]
        }
      ],
      "source": [
        "question = \"\"\"def get_user_data(user_id):\n",
        "    print(f'Fetching data for user: {user_id}')\n",
        "    # Simulate fetching data from a database\n",
        "    if user_id == 1:\n",
        "        return {'id': 1, 'name': 'Alice', 'email': 'alice@example.com'}\n",
        "    else:\n",
        "        return None\n",
        "  refactor this code please\"\"\"\n",
        "commands = refactor_chain.invoke({\"question\": question})\n",
        "print(commands)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTYjysguELeL"
      },
      "source": [
        "# Evaluating Faithfulness & Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1391f8f5",
        "outputId": "d1d77a83-e180-454c-ae4c-cc6e5277d5a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation dataset_df created successfully:\n",
            "                                            question  \\\n",
            "0  def get_user_data(user_id):\\n    print(f'Fetch...   \n",
            "\n",
            "                                            contexts  \\\n",
            "0  [All user inputs must be thoroughly validated ...   \n",
            "\n",
            "                                              answer  \\\n",
            "0  Critique: The provided code snippet has severa...   \n",
            "\n",
            "                                       ground_truths  \n",
            "0  The code uses print() for logging instead of a...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "ground_truth_answer_list = [\n",
        "    \"The code uses print() for logging instead of app_logger, lacks a docstring, and does not perform input validation. It should use app_logger for all logging, include a Google-format docstring, and validate user_id to prevent vulnerabilities.\",\n",
        "    \"import logging\\n\\napp_logger = logging.getLogger(__name__)\\napp_logger.setLevel(logging.INFO)\\n\\nif not app_logger.handlers:\\n    handler = logging.StreamHandler()\\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\\n    handler.setFormatter(formatter)\\n    app_logger.addHandler(handler)\\n\\ndef get_user_data(user_id):\\n    \\\"\\\"\\\"Fetches user data from a simulated database.\\n\\n    Validates the user_id and logs the fetching attempt before returning\\n    simulated user data.\\n\\n    Args:\\n        user_id: The unique identifier of the user to fetch. Must be a positive integer.\\n\\n    Returns:\\n        A dictionary containing user data (id, name, email) if found and valid,\\n        otherwise None.\\n    \\\"\\\"\\\"\\n    if not isinstance(user_id, int) or user_id <= 0:\\n        app_logger.warning(f\\\"Invalid user_id provided: {user_id}. Must be a positive integer.\\\")\\n        return None\\n\\n    app_logger.info(f'Fetching data for user: {user_id}')\\n    if user_id == 1:\\n        return {'id': 1, 'name': 'Alice', 'email': 'alice@example.com'}\\n    else:\\n        return None\"\n",
        "]\n",
        "ground_truth_answer = \"\\n---\\n\".join(ground_truth_answer_list)\n",
        "\n",
        "retrieved_docs = multiquery_retriever.invoke(question)\n",
        "contexts = [doc.page_content for doc in retrieved_docs]\n",
        "\n",
        "generated_output = refactor_chain.invoke({\"question\": question})\n",
        "answer_critique = generated_output[\"critique\"]\n",
        "answer_refactored_code = generated_output[\"refactored_code\"]\n",
        "\n",
        "generated_answer = f\"Critique: {answer_critique}\\n\\nRefactored Code: {answer_refactored_code}\"\n",
        "\n",
        "dataset_df = pd.DataFrame({\n",
        "    'question': [question],\n",
        "    'contexts': [contexts],\n",
        "    'answer': [generated_answer],\n",
        "    'ground_truths': [ground_truth_answer]\n",
        "})\n",
        "\n",
        "print(\"Evaluation dataset_df created successfully:\")\n",
        "print(dataset_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9NKfwNmOE_I0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179,
          "referenced_widgets": [
            "d862a259c7cd4394a6a73f291142084b",
            "646eccad80f34781ad2a5014a500b874",
            "01442423ea6345fa89e278c8338f9de1",
            "179048a445cc442ebae3e564b1b21c38",
            "89943c065ddd4a0f97f084fcf56e2203",
            "294e68ae19644560ba08367cb2ff0b8a",
            "5361d957e4e74b14aad50b3ab038a0ac",
            "cfde852168c143d88e3a84060f27e376",
            "1d4c6de4c9ea46b1985cea5632941154",
            "3634da1c36d545238b401b44934e027f",
            "30e39fc0bcef4af39b9997e0a606e66c"
          ]
        },
        "outputId": "ebe45080-18f0-42bb-e905-cc0c6bb4e12c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2881639327.py:3: DeprecationWarning: Importing faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import faithfulness\n",
            "  from ragas.metrics import faithfulness, context_recall\n",
            "/tmp/ipython-input-2881639327.py:3: DeprecationWarning: Importing context_recall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_recall\n",
            "  from ragas.metrics import faithfulness, context_recall\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d862a259c7cd4394a6a73f291142084b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ragas Evaluation Results:\n",
            "{'faithfulness': 0.3889, 'context_recall': 1.0000}\n"
          ]
        }
      ],
      "source": [
        "from ragas import evaluate\n",
        "from datasets import Dataset\n",
        "from ragas.metrics import faithfulness, context_recall\n",
        "\n",
        "ragas_dataset = Dataset.from_pandas(dataset_df)\n",
        "\n",
        "result = evaluate(\n",
        "    ragas_dataset,\n",
        "    llm=model,\n",
        "    embeddings=embeddings,\n",
        "    metrics=[ faithfulness, context_recall ],\n",
        "    column_map={ \"reference\": \"ground_truths\" },\n",
        ")\n",
        "\n",
        "print(\"Ragas Evaluation Results:\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building up The Agent"
      ],
      "metadata": {
        "id": "oqZ-MOcXQFt0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01a7a7f5",
        "outputId": "136acb63-3d0e-4c24-95a0-aeacf529ffe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Specialized retrievers 'style_guide_retriever' and 'security_policy_retriever' created.\n"
          ]
        }
      ],
      "source": [
        "style_guide_retriever = vectorstore.as_retriever(search_kwargs={\"filter\": {\"Header 1\": \"Style Guide\"}})\n",
        "security_policy_retriever = vectorstore.as_retriever(search_kwargs={\"filter\": {\"Header 1\": \"Security Policy\"}})\n",
        "\n",
        "print(\"Specialized retrievers 'style_guide_retriever' and 'security_policy_retriever' created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd63159b",
        "outputId": "88f98f6a-3618-4339-f89c-86bc50568900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Specialized tools 'style_guide_tool' and 'security_policy_tool' created.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import Tool\n",
        "\n",
        "style_guide_tool = Tool(\n",
        "    name=\"style_guide_retriever\",\n",
        "    description=\"Useful for retrieving information about the company's coding style guide.\",\n",
        "    func=style_guide_retriever.invoke,\n",
        ")\n",
        "\n",
        "security_policy_tool = Tool(\n",
        "    name=\"security_policy_retriever\",\n",
        "    description=\"Useful for retrieving information about the company's security policies.\",\n",
        "    func=security_policy_retriever.invoke,\n",
        ")\n",
        "\n",
        "print(\"Specialized tools 'style_guide_tool' and 'security_policy_tool' created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61acffec",
        "outputId": "c3e85203-8728-4256-951a-994aad50ff16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent and AgentExecutor created with specialized tools.\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.agents.structured_output import ToolStrategy\n",
        "\n",
        "tools = [style_guide_tool, security_policy_tool]\n",
        "agent = create_agent(\n",
        "    deterministic_model,\n",
        "    tools=tools,\n",
        "    response_format=ToolStrategy(RAGRefactorSuggestion),\n",
        "    system_prompt=\"You are a helpful assistant that can answer questions about coding style guides and security policies.\",\n",
        ")\n",
        "\n",
        "print(\"Agent and AgentExecutor created with specialized tools.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUY_d8S_UYRg",
        "outputId": "ba8c4315-a23a-475d-871d-590b02ac3d51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent's Refactoring Suggestion:\n",
            "critique=\"The original code violates the company's style guide by lacking a proper docstring for the `calculateResult` function. Furthermore, it breaches the security policy by hardcoding a `secret_api_key`. Additionally, the use of `print()` statements for logging is discouraged; `app_logger` should be used instead.\" refactored_code='\\nimport os\\n\\ndef calculate_result(some_value):\\n    \"\"\"Calculates a result based on the input value.\\n\\n    This function processes `some_value` and determines whether an\\n    API key would be used based on its magnitude.\\n\\n    Args:\\n        some_value: The numeric value to process.\\n\\n    Returns:\\n        The input value multiplied by 2.\\n    \"\"\"\\n    # As per security policy, use app_logger.info() instead of print() for logging.\\n    print(f\"Calculating result for {some_value}\")\\n    if some_value > 10:\\n        # Security Policy: API keys must be loaded from environment variables, not hardcoded.\\n        secret_api_key = os.getenv(\"SECRET_API_KEY\")\\n        if secret_api_key:\\n            print(\"Using API key for calculation\")\\n        else:\\n            print(\"Warning: SECRET_API_KEY environment variable not set.\")\\n    else:\\n        print(\"No API key needed\")\\n    return some_value * 2\\n' changes_made='1.  **Added a Google-formatted docstring** to the `calculate_result` function, explaining its purpose, arguments, and return value, adhering to the \\'Docstrings\\' style guide.\\n2.  **Replaced the hardcoded `secret_api_key`** with a call to `os.getenv(\"SECRET_API_KEY\")`, ensuring that the API key is loaded from an environment variable as required by the \\'API Keys\\' security policy. An `import os` statement was added.\\n3.  **Renamed the function** from `calculateResult` to `calculate_result` to comply with the snake_case naming convention (implied by \"All variables must be snake_case\" and common PEP 8 practices).\\n4.  **Added comments** indicating that `print()` statements should be replaced with `app_logger.info()` calls for proper logging, aligning with the \\'Logging\\' security policy.' policy_citations=['Style Guide - Docstrings', 'Security Policy - API Keys', 'Security Policy - Logging', 'Style Guide - Variable Naming']\n",
            "\n",
            "To view the detailed 'Think' -> 'Act' -> 'Observe' flow and tool usage, please check the LangSmith console. The trace for this execution will be available there.\n"
          ]
        }
      ],
      "source": [
        "question = \"\"\"\n",
        "def calculateResult(some_value):\n",
        "    # This function lacks a proper docstring.\n",
        "    print(f\"Calculating result for {some_value}\")\n",
        "    if some_value > 10:\n",
        "        secret_api_key = \"my_hardcoded_key\" # This is a hardcoded secret.\n",
        "        print(\"Using API key for calculation\")\n",
        "    else:\n",
        "        print(\"No API key needed\")\n",
        "    return some_value * 2\n",
        "\n",
        "refactor this code snippet to adhere to company style guidelines and security policies.\n",
        "\"\"\"\n",
        "\n",
        "result = agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": question}]\n",
        "})\n",
        "\n",
        "print(\"Agent's Refactoring Suggestion:\")\n",
        "print(result[\"structured_response\"])\n",
        "print(\"\\nTo view the detailed 'Think' -> 'Act' -> 'Observe' flow and tool usage, please check the LangSmith console. The trace for this execution will be available there.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "WPB1yPh9QMrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "# Function to load data\n",
        "def Load_Data(filename):\n",
        "print(f\"Loading {filename}...\")\n",
        "import pandas as pd\n",
        "df = pd.read_csv(filename)\n",
        "return df\n",
        "refactor this code please\n",
        "\"\"\"\n",
        "\n",
        "result = agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": question}]\n",
        "})\n",
        "\n",
        "print(\"Agent's Refactoring Suggestion:\")\n",
        "print(result[\"structured_response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkbw6nYDQNB3",
        "outputId": "f108cfcd-b584-4367-b61b-63e310596260"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent's Refactoring Suggestion:\n",
            "critique=\"The original code has several issues:\\n1.  **Function Naming:** The function `Load_Data` uses `PascalCase` with an underscore, which does not conform to the company's `snake_case` convention for variables (and implicitly functions in Python).\\n2.  **Import Statement Placement:** The `import pandas as pd` statement is placed inside the function, which is inefficient as it re-imports the module every time the function is called. Imports should generally be at the top of the file.\\n3.  **Logging:** It uses `print()` for logging, which is explicitly prohibited by the company's security policy for production code.\\n4.  **Error Handling:** It lacks robust error handling for common file-related issues like `FileNotFoundError`, `EmptyDataError`, or parsing errors.\\n5.  **Docstring:** The function lacks a comprehensive docstring describing its purpose, arguments, and return value.\" refactored_code='import pandas as pd\\n\\n# Assume \\'app_logger\\' is configured and available globally or imported\\n# from a central logging utility as per company policy.\\n# Example: from my_project.utils import app_logger\\n\\ndef load_data(filename: str):\\n    \"\"\"Loads data from a CSV file into a pandas DataFrame.\\n\\n    Args:\\n        filename: The path to the CSV file.\\n\\n    Returns:\\n        A pandas DataFrame containing the loaded data.\\n\\n    Raises:\\n        FileNotFoundError: If the specified file does not exist.\\n        pd.errors.EmptyDataError: If the file is empty.\\n        pd.errors.ParserError: If the file cannot be parsed.\\n    \"\"\"\\n    app_logger.info(f\"Attempting to load data from {filename}...\")\\n\\n    try:\\n        df = pd.read_csv(filename)\\n        app_logger.info(f\"Successfully loaded data from {filename}.\")\\n        return df\\n    except FileNotFoundError:\\n        app_logger.error(f\"Error: The file \\'{filename}\\' was not found.\")\\n        raise\\n    except pd.errors.EmptyDataError:\\n        app_logger.error(f\"Error: The file \\'{filename}\\' is empty.\")\\n        raise\\n    except pd.errors.ParserError as e:\\n        app_logger.error(f\"Error parsing file \\'{filename}\\': {e}\")\\n        raise\\n    except Exception as e:\\n        app_logger.error(f\"An unexpected error occurred while loading \\'{filename}\\': {e}\")\\n        raise' changes_made=\"1.  **Renamed the function** from `Load_Data` to `load_data` to comply with the `snake_case` naming convention.\\n2.  **Moved the `pandas` import** to the top of the file (or outside the function) for better performance and adherence to standard Python practices.\\n3.  **Replaced `print()` with `app_logger.info()` and `app_logger.error()`** calls for logging, as required by the security policy. Added a note that `app_logger` should be configured as per company standards.\\n4.  **Added a comprehensive Google-style docstring** to describe the function's purpose, arguments, return value, and potential exceptions.\\n5.  **Implemented `try-except` blocks** to handle `FileNotFoundError`, `pd.errors.EmptyDataError`, `pd.errors.ParserError`, and a general `Exception` during file loading, providing more robust error management and clearer logging for failures.\\n6.  **Added type hints** for better code readability and maintainability.\" policy_citations=['Style Guide -> Variable Naming', 'Style Guide -> Docstrings', 'Security Policy -> Logging']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6hxuSzJY3OcqdP+aU5GO2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}